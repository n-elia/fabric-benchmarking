{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP_1: Nominal Performances\n",
    "\n",
    "EXP_1 benchmarks are executed against the [HyperWatchdog](https://gitlab.com/ecs-lab/hyper-watchdog) smart contract, with:\n",
    "\n",
    "- the use-case-specific working load\n",
    "- variable network conditions\n",
    "\n",
    "The aim is to evaluate the performance of the HyperWatchdog smart contract when subject to a realistic working load and variable network conditions, including a real-world network emulation.\n",
    "Note: the endorsement policy is set to majority, therefore in this experiment the number of endorsers is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: restart kernel after installing packages!\n",
    "%pip install pandas\n",
    "%pip install plotly\n",
    "%pip install nbformat\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Settings\n",
    "NOTEBOOK_NAME = \"exp_1\"\n",
    "CALIPER_REPORTS_FILENAMES_START_WITH = None # Set None to disable filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "\n",
    "The following code block parses the data from the html reports generated by Caliper and stores data into a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_caliper_reports_dir_path = [\n",
    "    [\"..\", \"launcher\", \"results\", \"exp_1_nominal_performances\"],\n",
    "    ]\n",
    "target_caliper_reports_dir = [os.path.join(*p) for p in target_caliper_reports_dir_path]\n",
    "target_reports_filename_begin_with = CALIPER_REPORTS_FILENAMES_START_WITH # Filename filter\n",
    "export_filename = NOTEBOOK_NAME + \"_results.csv\"\n",
    "\n",
    "columns = [\n",
    "    \"Bechmark\",\n",
    "    \"Name\",\n",
    "    \"Succ\",\n",
    "    \"Fail\",\n",
    "    \"Send Rate (TPS)\",\n",
    "    \"Max Latency (s)\",\n",
    "    \"Min Latency (s)\",\n",
    "    \"Avg Latency (s)\",\n",
    "    \"Throughput (TPS)\",\n",
    "]\n",
    "rows = []\n",
    "\n",
    "def parse_reports(reports_dir, output_list):\n",
    "    for filename in os.listdir(reports_dir):\n",
    "        # Filter by filename\n",
    "        filepath = os.path.join(reports_dir, filename)\n",
    "        if target_reports_filename_begin_with is not None and\\\n",
    "           target_reports_filename_begin_with not in filepath:\n",
    "            continue\n",
    "\n",
    "        # Skip directories\n",
    "        if os.path.isdir(filepath):\n",
    "            continue\n",
    "\n",
    "        with open(filepath, \"r\") as fp:\n",
    "            state = 0\n",
    "            for line in fp.readlines():\n",
    "                line = line.strip()\n",
    "                if state == 0 and \"Performance metrics\" in line:\n",
    "                    state = 1\n",
    "                if state > 0 and \"</table>\" in line:\n",
    "                    state = 0\n",
    "                # if state==1 and \"<th>\" in line:\n",
    "                #    key = [l.split(\"</th>\")[0] for l in line.split(\"<th>\")[1:]]\n",
    "                #    print(key)\n",
    "                if state == 1 and \"<td>\" in line:\n",
    "                    output_list.append(\n",
    "                        [filepath] + [l.split(\"</td>\")[0] for l in line.split(\"<td>\")[1:]]\n",
    "                    )\n",
    "                    # print(values)\n",
    "                if state > 0:\n",
    "                    pass\n",
    "\n",
    "for reports_dir in target_caliper_reports_dir:\n",
    "    parse_reports(reports_dir, rows)\n",
    "\n",
    "with open(export_filename, \"w\") as fp:\n",
    "    print(\";\".join(columns), file=fp)\n",
    "    for row in rows:\n",
    "        print(\";\".join(row), file=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and preprocess\n",
    "\n",
    "The following code block imports the .csv file generated by the parsing code block.\n",
    "Data is stored in a pandas dataframe.\n",
    "\n",
    "Also, new columns are added to the dataframe to store the data in a more convenient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pd.read_csv(export_filename, sep=\";\")\n",
    "\n",
    "# Create two new columns \"Chunk Length\" and \"Requested TPS\" from the column \"Name\"\n",
    "source_df[\"Chunk Length\"] = source_df[\"Name\"].apply(lambda x: [int(i) for i in \"\".join([i for i in x if not i.isalpha()]).strip().split()][0])\n",
    "# df[\"Requested TPS\"] = df[\"Name\"].apply(lambda x: [int(i) for i in \"\".join([i for i in x if not i.isalpha()]).strip().split()][1])\n",
    "\n",
    "# Create a new column \"Benchmark ID\" from the column \"Bechmark\"\n",
    "source_df[\"Benchmark ID\"] = source_df[\"Bechmark\"].apply(lambda x: x.split(\"/\")[-1].split(\"_\")[1].split(\".\")[0])\n",
    "print(\"Benchmark IDs detected:\", source_df[\"Benchmark ID\"].unique())\n",
    "\n",
    "# Create a new column \"Success Rate\" from the column \"Succ\" and \"Fail\"\n",
    "source_df[\"Success Rate\"] = source_df[\"Succ\"] / (source_df[\"Succ\"] + source_df[\"Fail\"])\n",
    "\n",
    "# Create a new column \"Transaction Size (KiB)\" from the column \"Chunk Length\" considering that each transaction is 580 bytes\n",
    "# Round the result as integer\n",
    "source_df[\"Transaction Size (Byte)\"] = source_df[\"Chunk Length\"] * 580\n",
    "source_df[\"Transaction Size (Byte)\"] = source_df[\"Transaction Size (Byte)\"].apply(lambda x: round(x))\n",
    "\n",
    "# Function to extract new features from the filename\n",
    "def extract_feature_from_filename(inputFilename, featureTag: str, targetType = None):\n",
    "    filename = inputFilename.split(\"/\")[-1]\n",
    "    params = filename.split(\".\")[0].split(\"_\")\n",
    "    params[-1] = params[-1].split(\".\")[0]\n",
    "\n",
    "    if featureTag in params:\n",
    "        i = params.index(featureTag)\n",
    "        # Cast to the target type\n",
    "        if targetType is not None:\n",
    "            if targetType == \"int\":\n",
    "                return int(params[i + 1])\n",
    "            elif targetType == \"float\":\n",
    "                return float(params[i + 1])\n",
    "            elif targetType == \"str\":\n",
    "                return params[i + 1]\n",
    "        return params[i + 1]\n",
    "    else:\n",
    "        # If the feature is not found, return \"ideal\"\n",
    "        return \"ideal\"\n",
    "\n",
    "# Create new columns from the filename\n",
    "for feature_tag, column_name, column_type in [\n",
    "    (\"pl\", \"Network Packet Loss (%)\", \"int\"),\n",
    "    (\"thr\", \"Network Max Throughput (Mbps)\", \"int\"),\n",
    "    (\"del\", \"Network Avg Latency (ms)\", \"int\"),\n",
    "    (\"jit\", \"Network Jitter (ms)\", \"int\"),\n",
    "    ]:\n",
    "    source_df[column_name] = source_df[\"Bechmark\"].apply(lambda x: extract_feature_from_filename(\n",
    "        inputFilename=x,\n",
    "        featureTag=feature_tag,\n",
    "        targetType=column_type,\n",
    "        ))\n",
    "\n",
    "# Create a new column \"Network Handicaps\" from all the network features, containing a string with all the features\n",
    "def parse_row(row_value, column_name):\n",
    "    if row_value == \"ideal\":\n",
    "        return \"\"\n",
    "    elif column_name == \"Network Packet Loss (%)\":\n",
    "        return \"l\"\n",
    "    elif column_name == \"Network Max Throughput (Mbps)\":\n",
    "        return \"t\"\n",
    "    elif column_name == \"Network Avg Latency (ms)\":\n",
    "        return \"d\"\n",
    "    elif column_name == \"Network Jitter (ms)\":\n",
    "        return \"j\"\n",
    "    \n",
    "source_df[\"Network Handicaps\"] = source_df.apply(lambda x: \" \".join([parse_row(x[column_name], column_name) for column_name in [\n",
    "    \"Network Packet Loss (%)\",\n",
    "    \"Network Max Throughput (Mbps)\",\n",
    "    \"Network Avg Latency (ms)\",\n",
    "    \"Network Jitter (ms)\",\n",
    "    ]]), axis=1)\n",
    "\n",
    "# Evaluate data consistency\n",
    "def eval_consistency(df: pd.DataFrame):\n",
    "    # Create new column \"Consistency\" of type boolean and set it to True\n",
    "    df[\"Consistency\"] = True\n",
    "\n",
    "    for row in df.iterrows():\n",
    "        row_consistency = True\n",
    "\n",
    "        filename = row[1][\"Bechmark\"].split(\"/\")[-1]\n",
    "        params = filename.split(\".\")[0].split(\"_\")\n",
    "\n",
    "        for i in range(len(params)):\n",
    "            if params[i] == 'tps':\n",
    "                if int(params[i+1]) != row[1][\"Requested TPS\"]:\n",
    "                    row_consistency = False\n",
    "            elif params[i] == 'chunklen':\n",
    "                if int(params[i+1]) != row[1][\"Chunk Length\"]:\n",
    "                    row_consistency = False\n",
    "        \n",
    "        if row_consistency == False:\n",
    "            df.loc[row[0], \"Consistency\"] = False\n",
    "\n",
    "eval_consistency(source_df)\n",
    "\n",
    "# Check that none of the rows is inconsistent\n",
    "if False in source_df[\"Consistency\"].values:\n",
    "    print(\"Inconsistency detected!\")\n",
    "\n",
    "    print(\"Inconsistent rows:\")\n",
    "    print(source_df[source_df[\"Consistency\"] == False][\"Bechmark\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "### Throughput at different network conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a new dataframe containing only the rows with \"Benchmark ID\" equal to one of the values contained in the list\n",
    "df = source_df[source_df[\"Benchmark ID\"] == \"11\"]\n",
    "\n",
    "def group_network_conditions(s):\n",
    "    network_conditions = \"\"\n",
    "\n",
    "    for column_name in [\"Network Packet Loss (%)\", \"Network Max Throughput (Mbps)\", \"Network Avg Latency (ms)\", \"Network Jitter (ms)\"]:\n",
    "        if s[column_name] != \"ideal\":\n",
    "            name = column_name.lstrip(\"Network\").split(\"(\")[0].strip() # Before the first \"(\"\n",
    "            value = s[column_name] # The value\n",
    "            unit = str(column_name.split('(')[1].strip(\")\")).strip() # Inside the parentheses\n",
    "            network_conditions += f\",<br>{name} {value}{unit}\"\n",
    "    \n",
    "    if network_conditions == \"\":\n",
    "        return \"Ideal\"\n",
    "    else:\n",
    "        return network_conditions[5:]\n",
    "\n",
    "# Create a new column \"Conditions\" grouping the network conditions\n",
    "df[\"Network Conditions\"] = df.apply(lambda x: group_network_conditions(x), axis=1)\n",
    "\n",
    "cds = df[\"Network Conditions\"].unique() # All the different network conditions\n",
    "for i in range(len(cds)):\n",
    "    print(f\"Network condition {i}: {cds[i]}\")\n",
    "\n",
    "# Sort dataframe\n",
    "df_sorted = df.sort_values(by=[\"Network Conditions\", \"Transaction Size (Byte)\"])\n",
    "fig = px.line(df_sorted, x='Transaction Size (Byte)', color=\"Network Conditions\", y=\"Throughput (TPS)\", markers=True, template=\"simple_white\")\n",
    "\n",
    "# Set log scale\n",
    "fig.update_layout(\n",
    "    xaxis_type=\"log\",\n",
    "    # yaxis_type=\"log\",\n",
    ")\n",
    "\n",
    "# Add title\n",
    "# fig.update_layout(\n",
    "    # title=\"Throughput vs Transaction Size for different network conditions\",\n",
    "    # title_x=0.5, # Center title\n",
    "    # xaxis_title=\"Chunk Length\",\n",
    "    # yaxis_title=\"Average Throughput (TPS)\",\n",
    "# )\n",
    "\n",
    "# Add grid\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set border pane lines\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "\n",
    "# Set cathegories title\n",
    "fig.update_legends(title_text=\"Network Conditions\")\n",
    "\n",
    "# Center the legend\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.5,\n",
    "    xanchor=\"left\",\n",
    "    x=1.02\n",
    "))\n",
    "\n",
    "# Rezize before showing\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=400,\n",
    "    # Resize text\n",
    "    font=dict(\n",
    "        size=18,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Requested TPS\n",
    "multiplier = 580\n",
    "x = [i*multiplier for i in [208, 417, 833, 1666, 4165, 8330, 12495, 16660]]\n",
    "y = [4.0, 2.0, 1.0, 0.5, 0.2, 0.1, 0.1, 0.1]\n",
    "fig.add_trace(px.scatter(x=x, y=y).data[0].\n",
    "              update(name=\"Requested TPS\").\n",
    "              update(mode=\"markers\").\n",
    "              update(\n",
    "                  marker=dict(size=8, symbol=\"line-ew\", line=dict(width=2, color=\"Teal\"))).\n",
    "                  update(showlegend=True))\n",
    "\n",
    "# Save EPS figure\n",
    "# fig.write_image(\"exp_1_graph_1_log_size_throughput_vm.eps\", engine=\"kaleido\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg latency at different network conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a new dataframe containing only the rows with \"Benchmark ID\" equal to one of the values contained in the list\n",
    "df = source_df[source_df[\"Benchmark ID\"].isin([\"11\", \"09\"])]\n",
    "\n",
    "def group_network_conditions(s):\n",
    "    network_conditions = \"\"\n",
    "\n",
    "    for column_name in [\"Network Packet Loss (%)\", \"Network Max Throughput (Mbps)\", \"Network Avg Latency (ms)\", \"Network Jitter (ms)\"]:\n",
    "        if s[column_name] != \"ideal\":\n",
    "            name = column_name.lstrip(\"Network\").split(\"(\")[0].strip() # Before the first \"(\"\n",
    "            value = s[column_name] # The value\n",
    "            unit = str(column_name.split('(')[1].strip(\")\")).strip() # Inside the parentheses\n",
    "            network_conditions += f\",<br>{name} {value}{unit}\"\n",
    "    \n",
    "    if network_conditions == \"\":\n",
    "        return \"Ideal\"\n",
    "    else:\n",
    "        return network_conditions[5:]\n",
    "\n",
    "# Create a new column \"Conditions\" grouping the network conditions\n",
    "df[\"Network Conditions\"] = df.apply(lambda x: group_network_conditions(x), axis=1)\n",
    "\n",
    "cds = df[\"Network Conditions\"].unique() # All the different network conditions\n",
    "for i in range(len(cds)):\n",
    "    print(f\"Network condition {i}: {cds[i]}\")\n",
    "\n",
    "# Sort dataframe\n",
    "df_filtered = df[df[\"Benchmark ID\"].isin([\"11\"])]\n",
    "df_sorted = df_filtered.sort_values(by=[\"Network Conditions\", \"Transaction Size (Byte)\"])\n",
    "fig2 = px.line(df_sorted, x='Transaction Size (Byte)', color=\"Network Conditions\", y=\"Avg Latency (s)\", markers=True, template=\"simple_white\")\n",
    "\n",
    "# Set log scale\n",
    "fig2.update_layout(\n",
    "    xaxis_type=\"log\",\n",
    "    # yaxis_type=\"log\",\n",
    ")\n",
    "\n",
    "# Add title\n",
    "# fig2.update_layout(\n",
    "    # title=\"Avg Latency vs Transaction Size for different network conditions\",\n",
    "    # title_x=0.5, # Center title\n",
    "    # xaxis_title=\"Chunk Length\",\n",
    "    # yaxis_title=\"Average Throughput (TPS)\",\n",
    "# )\n",
    "\n",
    "# Add grid\n",
    "fig2.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set border pane lines\n",
    "fig2.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "fig2.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "\n",
    "# Set cathegories title\n",
    "fig2.update_legends(title_text=\"Network Conditions\")\n",
    "\n",
    "# Center the legend\n",
    "fig2.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.5,\n",
    "    xanchor=\"left\",\n",
    "    x=1.02\n",
    "))\n",
    "\n",
    "# Rezize before showing\n",
    "fig2.update_layout(\n",
    "    width=1000,\n",
    "    height=400,\n",
    "    # Resize text\n",
    "    font=dict(\n",
    "        size=18,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Save EPS figure\n",
    "# fig2.write_image(\"exp_1_graph_2_log_size_latency_vm.eps\", engine=\"kaleido\")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg latency at different network conditions for different block configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe containing only the experiment results with realistic network conditions\n",
    "df = source_df[source_df[\"Benchmark ID\"].isin([\"11\", \"09\"])]\n",
    "df = df[df[\"Network Handicaps\"] == \"l t d j\"]\n",
    "\n",
    "def group_network_conditions(s):\n",
    "    network_conditions = \"\"\n",
    "\n",
    "    for column_name in [\"Network Packet Loss (%)\", \"Network Max Throughput (Mbps)\", \"Network Avg Latency (ms)\", \"Network Jitter (ms)\"]:\n",
    "        if s[column_name] != \"ideal\":\n",
    "            name = column_name.lstrip(\"Network\").split(\"(\")[0].strip() # Before the first \"(\"\n",
    "            value = s[column_name] # The value\n",
    "            unit = str(column_name.split('(')[1].strip(\")\")).strip() # Inside the parentheses\n",
    "            network_conditions += f\",<br>{name} {value}{unit}\"\n",
    "    \n",
    "    if network_conditions == \"\":\n",
    "        return \"Ideal\"\n",
    "    else:\n",
    "        return network_conditions[5:]\n",
    "\n",
    "# Create a new column \"Conditions\" grouping the network conditions\n",
    "df[\"Network Conditions\"] = df.apply(lambda x: group_network_conditions(x), axis=1)\n",
    "\n",
    "cds = df[\"Network Conditions\"].unique() # All the different network conditions\n",
    "for i in range(len(cds)):\n",
    "    print(f\"Network condition {i}: {cds[i].replace('<br>', ' ')}\")\n",
    "\n",
    "df[\"Benchmark Name\"] = df[\"Benchmark ID\"].apply(lambda x: \"Standard<br>configuration\" if x == \"11\" else \"Alternative<br>configuration\")\n",
    "\n",
    "# Sort dataframe\n",
    "df_sorted = df.sort_values(by=[\"Benchmark ID\", \"Transaction Size (Byte)\"], ascending=False)\n",
    "fig = px.line(df_sorted, x='Transaction Size (Byte)', color=\"Benchmark Name\", y=\"Avg Latency (s)\", markers=True, template=\"simple_white\")\n",
    "\n",
    "# Set log scale\n",
    "fig.update_layout(\n",
    "    xaxis_type=\"log\",\n",
    "    # yaxis_type=\"log\",\n",
    ")\n",
    "\n",
    "# Add title\n",
    "fig.update_layout(\n",
    "    title=\"Average transaction latency for different block production configurations\",\n",
    "    title_x=0.5, # Center title\n",
    "    # xaxis_title=\"Chunk Length\",\n",
    "    # yaxis_title=\"Average Throughput (TPS)\",\n",
    ")\n",
    "\n",
    "# Add grid\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridwidth=1,\n",
    "        gridcolor='LightGrey',\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Set border pane lines\n",
    "fig.update_xaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "fig.update_yaxes(showline=True, linewidth=1, linecolor='black', mirror=True)\n",
    "\n",
    "# Set cathegories title\n",
    "fig.update_legends(title_text=\"Block Production\")\n",
    "\n",
    "# Center the legend\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"middle\",\n",
    "    y=0.5,\n",
    "    xanchor=\"left\",\n",
    "    x=1.02\n",
    "))\n",
    "\n",
    "# Rezize before showing\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=300,\n",
    "    # Resize text\n",
    "    font=dict(\n",
    "        size=12,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Save EPS figure\n",
    "# fig.write_image(\"exp_1_comparison_latency_with_diff_block_configs.eps\", scale=1, engine=\"kaleido\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
